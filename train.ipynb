{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "hide_input": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "name": "train.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nanhaishun/leaf_practice/blob/main/train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v6o6_rnZ-t4q",
        "outputId": "89d252e0-537d-44ef-eba9-7013f1dadc7d"
      },
      "source": [
        "!pip install git+https://github.com/albumentations-team/albumentations.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/albumentations-team/albumentations.git\n",
            "  Cloning https://github.com/albumentations-team/albumentations.git to /tmp/pip-req-build-xac_yrfc\n",
            "  Running command git clone -q https://github.com/albumentations-team/albumentations.git /tmp/pip-req-build-xac_yrfc\n",
            "Requirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from albumentations==0.5.2) (1.19.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from albumentations==0.5.2) (1.4.1)\n",
            "Requirement already satisfied: scikit-image>=0.16.1 in /usr/local/lib/python3.6/dist-packages (from albumentations==0.5.2) (0.16.2)\n",
            "Collecting imgaug>=0.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/66/b1/af3142c4a85cba6da9f4ebb5ff4e21e2616309552caca5e8acefe9840622/imgaug-0.4.0-py2.py3-none-any.whl (948kB)\n",
            "\u001b[K     |████████████████████████████████| 952kB 6.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.6/dist-packages (from albumentations==0.5.2) (3.13)\n",
            "Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from albumentations==0.5.2) (4.1.2.30)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.16.1->albumentations==0.5.2) (3.2.2)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.16.1->albumentations==0.5.2) (2.4.1)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.16.1->albumentations==0.5.2) (1.1.1)\n",
            "Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.16.1->albumentations==0.5.2) (7.0.0)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.16.1->albumentations==0.5.2) (2.5)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.6/dist-packages (from imgaug>=0.4.0->albumentations==0.5.2) (1.7.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from imgaug>=0.4.0->albumentations==0.5.2) (1.15.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations==0.5.2) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations==0.5.2) (1.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations==0.5.2) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations==0.5.2) (0.10.0)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->scikit-image>=0.16.1->albumentations==0.5.2) (4.4.2)\n",
            "Building wheels for collected packages: albumentations\n",
            "  Building wheel for albumentations (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for albumentations: filename=albumentations-0.5.2-cp36-none-any.whl size=81845 sha256=6b11a8bacb578d37c56a06cb1d438b89589b9901f19652c96a77773fbb2c1c4e\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-hj6kxq3k/wheels/e2/85/3e/2a40fac5cc1f43ced656603bb2fca1327b30ec7de1b1b66517\n",
            "Successfully built albumentations\n",
            "Installing collected packages: imgaug, albumentations\n",
            "  Found existing installation: imgaug 0.2.9\n",
            "    Uninstalling imgaug-0.2.9:\n",
            "      Successfully uninstalled imgaug-0.2.9\n",
            "  Found existing installation: albumentations 0.1.12\n",
            "    Uninstalling albumentations-0.1.12:\n",
            "      Successfully uninstalled albumentations-0.1.12\n",
            "Successfully installed albumentations-0.5.2 imgaug-0.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G4Jq847z-wrR",
        "outputId": "556d5e1b-cc07-4cda-b1ca-d4911936efc7"
      },
      "source": [
        "!pip install timm"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting timm\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/22/c6/ba02d533cec7329323c7d7a317ab49f673846ecef202d4cc40988b6b7786/timm-0.3.4-py3-none-any.whl (244kB)\n",
            "\r\u001b[K     |█▍                              | 10kB 12.8MB/s eta 0:00:01\r\u001b[K     |██▊                             | 20kB 10.4MB/s eta 0:00:01\r\u001b[K     |████                            | 30kB 9.9MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 40kB 8.3MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 51kB 5.2MB/s eta 0:00:01\r\u001b[K     |████████                        | 61kB 5.9MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 71kB 5.9MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 81kB 6.6MB/s eta 0:00:01\r\u001b[K     |████████████                    | 92kB 6.3MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 102kB 6.6MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 112kB 6.6MB/s eta 0:00:01\r\u001b[K     |████████████████                | 122kB 6.6MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 133kB 6.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 143kB 6.6MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 153kB 6.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 163kB 6.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 174kB 6.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 184kB 6.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 194kB 6.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 204kB 6.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 215kB 6.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 225kB 6.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 235kB 6.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 245kB 6.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (from timm) (0.8.1+cu101)\n",
            "Requirement already satisfied: torch>=1.4 in /usr/local/lib/python3.6/dist-packages (from timm) (1.7.0+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision->timm) (1.19.5)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision->timm) (7.0.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch>=1.4->timm) (3.7.4.3)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch>=1.4->timm) (0.8)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.4->timm) (0.16.0)\n",
            "Installing collected packages: timm\n",
            "Successfully installed timm-0.3.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "25PoLgqZ-Lrs"
      },
      "source": [
        "# 导入依赖的库\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from torch.cuda.amp import GradScaler\n",
        "from torch import nn\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "import timm\n",
        "import cv2\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from utils import utils\n",
        "from imp import reload\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "from albumentations import (\n",
        "    HorizontalFlip, VerticalFlip, IAAPerspective, ShiftScaleRotate, CLAHE, RandomRotate90,\n",
        "    Transpose, ShiftScaleRotate, Blur, OpticalDistortion, GridDistortion, HueSaturationValue,\n",
        "    IAAAdditiveGaussianNoise, GaussNoise, MotionBlur, MedianBlur, IAAPiecewiseAffine, RandomResizedCrop,\n",
        "    IAASharpen, IAAEmboss, RandomBrightnessContrast, Flip, OneOf, Compose, Normalize, Cutout, CoarseDropout,\n",
        "    ShiftScaleRotate, CenterCrop, Resize\n",
        ")\n",
        "reload(utils)\n",
        "rand_seed = 666\n",
        "utils.seed_everything(rand_seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lGhlS_WN-dLH",
        "outputId": "f5f123ea-79ee-4c73-b64b-4042fe003ab7"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IB9EmMir-Lrz"
      },
      "source": [
        "train_img_path = r'../data/train_images' #样本图片的路径\n",
        "train_csv_path = r'../data/train.csv' #训练集合标记CSV"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-xgGfj1-Lrz"
      },
      "source": [
        "# 训练集数据增强\n",
        "def get_train_transforms():\n",
        "    return Compose([\n",
        "        RandomResizedCrop(CFG['img_size'], CFG['img_size']),\n",
        "        Transpose(p=0.5),\n",
        "        HorizontalFlip(p=0.5),\n",
        "        VerticalFlip(p=0.5),\n",
        "        ShiftScaleRotate(p=0.5),\n",
        "        HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2, p=0.5),\n",
        "        RandomBrightnessContrast(brightness_limit=(-0.1, 0.1), contrast_limit=(-0.1, 0.1), p=0.5),\n",
        "        Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\n",
        "        CoarseDropout(p=0.5),\n",
        "        Cutout(p=0.5),\n",
        "        ToTensorV2(p=1.0),\n",
        "    ], p=1.)\n",
        "\n",
        "# 验证集数据增强\n",
        "def get_valid_transforms():\n",
        "    return Compose([\n",
        "        CenterCrop(CFG['img_size'], CFG['img_size'], p=1.),\n",
        "        Resize(CFG['img_size'], CFG['img_size']),\n",
        "        Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\n",
        "        ToTensorV2(p=1.0),\n",
        "    ], p=1.)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "as0rbIxY-Lr0"
      },
      "source": [
        "# 模型构建\n",
        "class CassvaImgClassifier(nn.Module):\n",
        "    def __init__(self, model_arch, n_class, pretrained=False):\n",
        "        super().__init__()\n",
        "        self.model = timm.create_model(model_arch, pretrained=pretrained)\n",
        "        n_features = self.model.classifier.in_features\n",
        "        self.model.classifier = nn.Linear(n_features, n_class)\n",
        "    def forward(self, x):\n",
        "        x = self.model(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWPa3cFR-Lr0"
      },
      "source": [
        "# 构建数据\n",
        "CFG = {\n",
        "    'img_size' : 512,\n",
        "    'epochs': 15,\n",
        "    'fold_num': 5,\n",
        "    'device': 'cpu',\n",
        "    'model_arch': 'tf_efficientnet_b4_ns',\n",
        "    'train_bs' : 2,\n",
        "    'valid_bs' : 2,\n",
        "    'num_workers' : 0,\n",
        "    'lr': 1e-4,\n",
        "    'weight_decay': 1e-6,\n",
        "    'T_0': 10,\n",
        "    'min_lr': 1e-6,\n",
        "}\n",
        "train = pd.read_csv(train_csv_path)\n",
        "folds = StratifiedKFold(n_splits=CFG['fold_num'],\n",
        "                        shuffle=True,\n",
        "                        random_state=rand_seed).split(\n",
        "                            np.arange(train.shape[0]), train.label.values)\n",
        "trn_transform = get_train_transforms()\n",
        "val_transform = get_valid_transforms()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t9tzO4rq-Lr0",
        "outputId": "d3a34095-9644-471e-8369-d349c2332003"
      },
      "source": [
        "fold_num = 0\n",
        "for fold, (trn_idx, val_idx) in enumerate(folds):\n",
        "    if fold == fold_num:\n",
        "        print('Training with {} started'.format(fold))\n",
        "        print('Train : {}, Val : {}'.format(len(trn_idx), len(val_idx)))\n",
        "        train_loader, val_loader = utils.prepare_dataloader(train,\n",
        "                                                          trn_idx,\n",
        "                                                          val_idx,\n",
        "                                                          data_root = train_img_path,\n",
        "                                                          trn_transform = trn_transform,\n",
        "                                                          val_transform = val_transform, \n",
        "                                                          bs = CFG['train_bs'], \n",
        "                                                          n_job = CFG['num_workers'])\n",
        "\n",
        "        device = torch.device(CFG['device'])\n",
        "\n",
        "        model = CassvaImgClassifier(CFG['model_arch'],\n",
        "                                    train.label.nunique(),\n",
        "                                    pretrained=True).to(device)\n",
        "        scaler = GradScaler()\n",
        "        optimizer = torch.optim.Adam(model.parameters(),\n",
        "                                     lr=CFG['lr'],\n",
        "                                     weight_decay=CFG['weight_decay'])\n",
        "\n",
        "        scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
        "            optimizer,\n",
        "            T_0=CFG['T_0'],\n",
        "            T_mult=1,\n",
        "            eta_min=CFG['min_lr'],\n",
        "            last_epoch=-1)\n",
        "\n",
        "        loss_tr = nn.CrossEntropyLoss().to(\n",
        "            device)\n",
        "        loss_fn = nn.CrossEntropyLoss().to(device)\n",
        "\n",
        "        for epoch in range(CFG['epochs']):\n",
        "            utils.train_one_epoch(epoch,\n",
        "                                model,\n",
        "                                loss_tr,\n",
        "                                optimizer,\n",
        "                                train_loader,\n",
        "                                device,\n",
        "                                scaler,\n",
        "                                scheduler=scheduler,\n",
        "                                schd_batch_update=False)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                utils.valid_one_epoch(epoch,\n",
        "                                    model,\n",
        "                                    loss_fn,\n",
        "                                    val_loader,\n",
        "                                    device)\n",
        "\n",
        "            torch.save(\n",
        "                model.state_dict(),\n",
        "                '../model/{}_fold_{}_{}'.format(CFG['model_arch'], fold, epoch))\n",
        "\n",
        "        del model, optimizer, train_loader, val_loader, scaler, scheduler\n",
        "        torch.cuda.empty_cache()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training with 0 started\n",
            "Train : 17117, Val : 4280\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/Users/wanjun/anaconda/envs/python36/lib/python3.6/site-packages/torch/cuda/amp/grad_scaler.py:115: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
            "  warnings.warn(\"torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\")\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/8559 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A/Users/wanjun/anaconda/envs/python36/lib/python3.6/site-packages/torch/cuda/amp/autocast_mode.py:114: UserWarning: torch.cuda.amp.autocast only affects CUDA ops, but CUDA is not available.  Disabling.\n",
            "  warnings.warn(\"torch.cuda.amp.autocast only affects CUDA ops, but CUDA is not available.  Disabling.\")\n",
            "\n",
            "\n",
            "\n",
            "epoch 0 loss: 1.6059:   0%|          | 0/8559 [00:07<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "epoch 0 loss: 1.6059:   0%|          | 1/8559 [00:07<18:46:41,  7.90s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "epoch 0 loss: 1.6060:   0%|          | 1/8559 [00:14<18:46:41,  7.90s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "epoch 0 loss: 1.6060:   0%|          | 2/8559 [00:14<17:35:07,  7.40s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m----------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m        Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-81-5cc2ef3384d2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     43\u001b[0m                                 \u001b[0mscaler\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m                                 \u001b[0mscheduler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m                                 schd_batch_update=False)\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/Desktop/比赛训练营/Kaggle木薯叶比赛/代码/code/src/utils/utils.py\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m(epoch, model, loss_fn, optimizer, train_loader, device, scaler, scheduler, schd_batch_update, accum_iter)\u001b[0m\n\u001b[1;32m    287\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_preds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_labels\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 计算 loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m         \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 对 loss scale, scale梯度\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0;31m# loss 正则,使用指数平均\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda/envs/python36/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda/envs/python36/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    130\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lT44oVd4-Lr2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
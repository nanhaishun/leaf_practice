{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "hide_input": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "name": "train.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nanhaishun/leaf_practice/blob/main/train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v6o6_rnZ-t4q",
        "outputId": "89d252e0-537d-44ef-eba9-7013f1dadc7d"
      },
      "source": [
        "!pip install git+https://github.com/albumentations-team/albumentations.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/albumentations-team/albumentations.git\n",
            "  Cloning https://github.com/albumentations-team/albumentations.git to /tmp/pip-req-build-xac_yrfc\n",
            "  Running command git clone -q https://github.com/albumentations-team/albumentations.git /tmp/pip-req-build-xac_yrfc\n",
            "Requirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from albumentations==0.5.2) (1.19.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from albumentations==0.5.2) (1.4.1)\n",
            "Requirement already satisfied: scikit-image>=0.16.1 in /usr/local/lib/python3.6/dist-packages (from albumentations==0.5.2) (0.16.2)\n",
            "Collecting imgaug>=0.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/66/b1/af3142c4a85cba6da9f4ebb5ff4e21e2616309552caca5e8acefe9840622/imgaug-0.4.0-py2.py3-none-any.whl (948kB)\n",
            "\u001b[K     |████████████████████████████████| 952kB 6.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.6/dist-packages (from albumentations==0.5.2) (3.13)\n",
            "Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from albumentations==0.5.2) (4.1.2.30)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.16.1->albumentations==0.5.2) (3.2.2)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.16.1->albumentations==0.5.2) (2.4.1)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.16.1->albumentations==0.5.2) (1.1.1)\n",
            "Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.16.1->albumentations==0.5.2) (7.0.0)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.16.1->albumentations==0.5.2) (2.5)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.6/dist-packages (from imgaug>=0.4.0->albumentations==0.5.2) (1.7.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from imgaug>=0.4.0->albumentations==0.5.2) (1.15.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations==0.5.2) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations==0.5.2) (1.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations==0.5.2) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations==0.5.2) (0.10.0)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->scikit-image>=0.16.1->albumentations==0.5.2) (4.4.2)\n",
            "Building wheels for collected packages: albumentations\n",
            "  Building wheel for albumentations (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for albumentations: filename=albumentations-0.5.2-cp36-none-any.whl size=81845 sha256=6b11a8bacb578d37c56a06cb1d438b89589b9901f19652c96a77773fbb2c1c4e\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-hj6kxq3k/wheels/e2/85/3e/2a40fac5cc1f43ced656603bb2fca1327b30ec7de1b1b66517\n",
            "Successfully built albumentations\n",
            "Installing collected packages: imgaug, albumentations\n",
            "  Found existing installation: imgaug 0.2.9\n",
            "    Uninstalling imgaug-0.2.9:\n",
            "      Successfully uninstalled imgaug-0.2.9\n",
            "  Found existing installation: albumentations 0.1.12\n",
            "    Uninstalling albumentations-0.1.12:\n",
            "      Successfully uninstalled albumentations-0.1.12\n",
            "Successfully installed albumentations-0.5.2 imgaug-0.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G4Jq847z-wrR",
        "outputId": "541cf917-0c4d-4eae-a3be-388e8848b5f1"
      },
      "source": [
        "!pip install timm"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: timm in /usr/local/lib/python3.6/dist-packages (0.3.4)\n",
            "Requirement already satisfied: torch>=1.4 in /usr/local/lib/python3.6/dist-packages (from timm) (1.7.0+cu101)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (from timm) (0.8.1+cu101)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.4->timm) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch>=1.4->timm) (3.7.4.3)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch>=1.4->timm) (0.8)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch>=1.4->timm) (1.19.5)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision->timm) (7.0.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xYER7dxyQAvH",
        "outputId": "0affa5cb-f62b-48ab-f59f-a780d4ad6ca5"
      },
      "source": [
        "!git clone https://github.com/nanhaishun/leaf_practice.git"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'leaf_practice'...\n",
            "remote: Enumerating objects: 12, done.\u001b[K\n",
            "remote: Counting objects:   8% (1/12)\u001b[K\rremote: Counting objects:  16% (2/12)\u001b[K\rremote: Counting objects:  25% (3/12)\u001b[K\rremote: Counting objects:  33% (4/12)\u001b[K\rremote: Counting objects:  41% (5/12)\u001b[K\rremote: Counting objects:  50% (6/12)\u001b[K\rremote: Counting objects:  58% (7/12)\u001b[K\rremote: Counting objects:  66% (8/12)\u001b[K\rremote: Counting objects:  75% (9/12)\u001b[K\rremote: Counting objects:  83% (10/12)\u001b[K\rremote: Counting objects:  91% (11/12)\u001b[K\rremote: Counting objects: 100% (12/12)\u001b[K\rremote: Counting objects: 100% (12/12), done.\u001b[K\n",
            "remote: Compressing objects:  12% (1/8)\u001b[K\rremote: Compressing objects:  25% (2/8)\u001b[K\rremote: Compressing objects:  37% (3/8)\u001b[K\rremote: Compressing objects:  50% (4/8)\u001b[K\rremote: Compressing objects:  62% (5/8)\u001b[K\rremote: Compressing objects:  75% (6/8)\u001b[K\rremote: Compressing objects:  87% (7/8)\u001b[K\rremote: Compressing objects: 100% (8/8)\u001b[K\rremote: Compressing objects: 100% (8/8), done.\u001b[K\n",
            "remote: Total 12 (delta 1), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (12/12), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "pQ61h0rjNySR",
        "outputId": "9b23e662-3f47-4f98-e5eb-10c9f6d018cc"
      },
      "source": [
        "import os\n",
        "os.getcwd()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "25PoLgqZ-Lrs"
      },
      "source": [
        "# 导入依赖的库\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from torch.cuda.amp import GradScaler\n",
        "from torch import nn\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "import timm\n",
        "import cv2\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from utils import utils\n",
        "from imp import reload\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "from albumentations import (\n",
        "    HorizontalFlip, VerticalFlip, IAAPerspective, ShiftScaleRotate, CLAHE, RandomRotate90,\n",
        "    Transpose, ShiftScaleRotate, Blur, OpticalDistortion, GridDistortion, HueSaturationValue,\n",
        "    IAAAdditiveGaussianNoise, GaussNoise, MotionBlur, MedianBlur, IAAPiecewiseAffine, RandomResizedCrop,\n",
        "    IAASharpen, IAAEmboss, RandomBrightnessContrast, Flip, OneOf, Compose, Normalize, Cutout, CoarseDropout,\n",
        "    ShiftScaleRotate, CenterCrop, Resize\n",
        ")\n",
        "reload(utils)\n",
        "rand_seed = 666\n",
        "utils.seed_everything(rand_seed)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lGhlS_WN-dLH",
        "outputId": "f5f123ea-79ee-4c73-b64b-4042fe003ab7"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ae3S34dzh6Pl",
        "outputId": "de42b5de-4fa2-47f5-dbec-59738bac9d31"
      },
      "source": [
        "!pip install kaggle"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.6/dist-packages (1.5.10)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.23.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.15.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.8.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.0.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (3.0.4)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.6/dist-packages (from python-slugify->kaggle) (1.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tnL8PZHKuLwo"
      },
      "source": [
        "从kaggle下载数据集"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LJjbhDLWthqd",
        "outputId": "1b5ce945-37c5-4dc4-ccff-ed781a347329"
      },
      "source": [
        "!mkdir -p ~/.kaggle \n",
        "!cp /content/kaggle.json ~/.kaggle/ \n",
        "!chmod 600 ~/.kaggle/kaggle.json \n",
        "#kaggle competitions download -c cassava-leaf-disease-classification\n",
        "!kaggle competitions download -c cassava-leaf-disease-classification -p '/content/data/'"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.10 / client 1.5.4)\n",
            "Downloading 2216849948.jpg to /content/data\n",
            "  0% 0.00/141k [00:00<?, ?B/s]\n",
            "100% 141k/141k [00:00<00:00, 55.6MB/s]\n",
            "Downloading ld_test00-1.tfrec to /content/data\n",
            "  0% 0.00/191k [00:00<?, ?B/s]\n",
            "100% 191k/191k [00:00<00:00, 59.1MB/s]\n",
            "Downloading 1001749118.jpg to /content/data\n",
            "  0% 0.00/135k [00:00<?, ?B/s]\n",
            "100% 135k/135k [00:00<00:00, 51.8MB/s]\n",
            "Downloading 1003442061.jpg to /content/data\n",
            "  0% 0.00/101k [00:00<?, ?B/s]\n",
            "100% 101k/101k [00:00<00:00, 89.1MB/s]\n",
            "Downloading 1003888281.jpg to /content/data\n",
            "  0% 0.00/110k [00:00<?, ?B/s]\n",
            "100% 110k/110k [00:00<00:00, 113MB/s]\n",
            "Downloading 1003987001.jpg to /content/data\n",
            "  0% 0.00/101k [00:00<?, ?B/s]\n",
            "100% 101k/101k [00:00<00:00, 83.2MB/s]\n",
            "Downloading 100042118.jpg to /content/data\n",
            "  0% 0.00/72.8k [00:00<?, ?B/s]\n",
            "100% 72.8k/72.8k [00:00<00:00, 61.7MB/s]\n",
            "Downloading 1000837476.jpg to /content/data\n",
            "  0% 0.00/104k [00:00<?, ?B/s]\n",
            "100% 104k/104k [00:00<00:00, 105MB/s]\n",
            "Downloading 1001320321.jpg to /content/data\n",
            "  0% 0.00/82.3k [00:00<?, ?B/s]\n",
            "100% 82.3k/82.3k [00:00<00:00, 69.2MB/s]\n",
            "Downloading 1003218714.jpg to /content/data\n",
            "  0% 0.00/127k [00:00<?, ?B/s]\n",
            "100% 127k/127k [00:00<00:00, 37.9MB/s]\n",
            "Downloading 100204014.jpg to /content/data\n",
            "  0% 0.00/170k [00:00<?, ?B/s]\n",
            "100% 170k/170k [00:00<00:00, 52.6MB/s]\n",
            "Downloading 1000812911.jpg to /content/data\n",
            "  0% 0.00/79.1k [00:00<?, ?B/s]\n",
            "100% 79.1k/79.1k [00:00<00:00, 68.7MB/s]\n",
            "Downloading 1002088496.jpg to /content/data\n",
            "  0% 0.00/131k [00:00<?, ?B/s]\n",
            "100% 131k/131k [00:00<00:00, 41.3MB/s]\n",
            "Downloading 1000015157.jpg to /content/data\n",
            "  0% 0.00/136k [00:00<?, ?B/s]\n",
            "100% 136k/136k [00:00<00:00, 118MB/s]\n",
            "Downloading 1000201771.jpg to /content/data\n",
            "  0% 0.00/158k [00:00<?, ?B/s]\n",
            "100% 158k/158k [00:00<00:00, 50.2MB/s]\n",
            "Downloading 1002394761.jpg to /content/data\n",
            "  0% 0.00/101k [00:00<?, ?B/s]\n",
            "100% 101k/101k [00:00<00:00, 88.7MB/s]\n",
            "Downloading 1000910826.jpg to /content/data\n",
            "  0% 0.00/100k [00:00<?, ?B/s]\n",
            "100% 100k/100k [00:00<00:00, 134MB/s]\n",
            "Downloading 1002255315.jpg to /content/data\n",
            "  0% 0.00/150k [00:00<?, ?B/s]\n",
            "100% 150k/150k [00:00<00:00, 147MB/s]\n",
            "Downloading 1001742395.jpg to /content/data\n",
            "  0% 0.00/99.7k [00:00<?, ?B/s]\n",
            "100% 99.7k/99.7k [00:00<00:00, 92.3MB/s]\n",
            "Downloading 1003298598.jpg to /content/data\n",
            "  0% 0.00/142k [00:00<?, ?B/s]\n",
            "100% 142k/142k [00:00<00:00, 179MB/s]\n",
            "Downloading 1000723321.jpg to /content/data\n",
            "  0% 0.00/119k [00:00<?, ?B/s]\n",
            "100% 119k/119k [00:00<00:00, 167MB/s]\n",
            "Downloading 1001723730.jpg to /content/data\n",
            "  0% 0.00/83.5k [00:00<?, ?B/s]\n",
            "100% 83.5k/83.5k [00:00<00:00, 66.1MB/s]\n",
            "Downloading ld_train03-1338.tfrec.zip to /content/data\n",
            " 97% 211M/217M [00:01<00:00, 98.4MB/s]\n",
            "100% 217M/217M [00:01<00:00, 118MB/s] \n",
            "Downloading ld_train00-1338.tfrec.zip to /content/data\n",
            " 98% 213M/217M [00:02<00:00, 84.4MB/s]\n",
            "100% 217M/217M [00:02<00:00, 107MB/s] \n",
            "Downloading ld_train01-1338.tfrec.zip to /content/data\n",
            " 93% 201M/215M [00:03<00:00, 69.8MB/s]\n",
            "100% 215M/215M [00:03<00:00, 72.0MB/s]\n",
            "Downloading ld_train07-1338.tfrec.zip to /content/data\n",
            " 98% 212M/216M [00:02<00:00, 116MB/s] \n",
            "100% 216M/216M [00:02<00:00, 93.5MB/s]\n",
            "Downloading ld_train04-1338.tfrec.zip to /content/data\n",
            " 93% 202M/216M [00:02<00:00, 93.8MB/s]\n",
            "100% 216M/216M [00:02<00:00, 109MB/s] \n",
            "Downloading ld_train12-1338.tfrec.zip to /content/data\n",
            " 98% 212M/216M [00:01<00:00, 85.7MB/s]\n",
            "100% 216M/216M [00:02<00:00, 112MB/s] \n",
            "Downloading ld_train13-1338.tfrec.zip to /content/data\n",
            " 96% 208M/217M [00:01<00:00, 124MB/s]\n",
            "100% 217M/217M [00:01<00:00, 130MB/s]\n",
            "Downloading ld_train05-1338.tfrec.zip to /content/data\n",
            "100% 214M/214M [00:02<00:00, 68.8MB/s]\n",
            "100% 214M/214M [00:02<00:00, 79.2MB/s]\n",
            "Downloading ld_train14-1338.tfrec.zip to /content/data\n",
            " 95% 204M/215M [00:03<00:00, 73.9MB/s]\n",
            "100% 215M/215M [00:03<00:00, 68.5MB/s]\n",
            "Downloading ld_train10-1338.tfrec.zip to /content/data\n",
            " 95% 206M/217M [00:01<00:00, 116MB/s]\n",
            "100% 217M/217M [00:02<00:00, 109MB/s]\n",
            "Downloading ld_train06-1338.tfrec.zip to /content/data\n",
            " 95% 204M/216M [00:01<00:00, 123MB/s]\n",
            "100% 216M/216M [00:01<00:00, 127MB/s]\n",
            "Downloading ld_train11-1338.tfrec.zip to /content/data\n",
            " 98% 214M/218M [00:01<00:00, 139MB/s]\n",
            "100% 218M/218M [00:01<00:00, 127MB/s]\n",
            "Downloading ld_train15-1327.tfrec.zip to /content/data\n",
            " 98% 209M/214M [00:01<00:00, 95.8MB/s]\n",
            "100% 214M/214M [00:02<00:00, 111MB/s] \n",
            "Downloading ld_train02-1338.tfrec.zip to /content/data\n",
            "100% 216M/216M [00:01<00:00, 126MB/s]\n",
            "\n",
            "Downloading ld_train09-1338.tfrec.zip to /content/data\n",
            "100% 216M/216M [00:01<00:00, 115MB/s] \n",
            "100% 216M/216M [00:02<00:00, 111MB/s]\n",
            "Downloading ld_train08-1338.tfrec.zip to /content/data\n",
            "100% 216M/217M [00:02<00:00, 131MB/s]\n",
            "100% 217M/217M [00:02<00:00, 81.4MB/s]\n",
            "Downloading label_num_to_disease_map.json to /content/data\n",
            "  0% 0.00/172 [00:00<?, ?B/s]\n",
            "100% 172/172 [00:00<00:00, 139kB/s]\n",
            "Downloading sample_submission.csv to /content/data\n",
            "  0% 0.00/32.0 [00:00<?, ?B/s]\n",
            "100% 32.0/32.0 [00:00<00:00, 31.0kB/s]\n",
            "Downloading train.csv to /content/data\n",
            "  0% 0.00/350k [00:00<?, ?B/s]\n",
            "100% 350k/350k [00:00<00:00, 112MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7hZzOa4tny-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IB9EmMir-Lrz"
      },
      "source": [
        "train_img_path = r'../data/train_images' #样本图片的路径\n",
        "train_csv_path = r'../data/train.csv' #训练集合标记CSV"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-xgGfj1-Lrz"
      },
      "source": [
        "# 训练集数据增强\n",
        "def get_train_transforms():\n",
        "    return Compose([\n",
        "        RandomResizedCrop(CFG['img_size'], CFG['img_size']),\n",
        "        Transpose(p=0.5),\n",
        "        HorizontalFlip(p=0.5),\n",
        "        VerticalFlip(p=0.5),\n",
        "        ShiftScaleRotate(p=0.5),\n",
        "        HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2, p=0.5),\n",
        "        RandomBrightnessContrast(brightness_limit=(-0.1, 0.1), contrast_limit=(-0.1, 0.1), p=0.5),\n",
        "        Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\n",
        "        CoarseDropout(p=0.5),\n",
        "        Cutout(p=0.5),\n",
        "        ToTensorV2(p=1.0),\n",
        "    ], p=1.)\n",
        "\n",
        "# 验证集数据增强\n",
        "def get_valid_transforms():\n",
        "    return Compose([\n",
        "        CenterCrop(CFG['img_size'], CFG['img_size'], p=1.),\n",
        "        Resize(CFG['img_size'], CFG['img_size']),\n",
        "        Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\n",
        "        ToTensorV2(p=1.0),\n",
        "    ], p=1.)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "as0rbIxY-Lr0"
      },
      "source": [
        "# 模型构建\n",
        "class CassvaImgClassifier(nn.Module):\n",
        "    def __init__(self, model_arch, n_class, pretrained=False):\n",
        "        super().__init__()\n",
        "        self.model = timm.create_model(model_arch, pretrained=pretrained)\n",
        "        n_features = self.model.classifier.in_features\n",
        "        self.model.classifier = nn.Linear(n_features, n_class)\n",
        "    def forward(self, x):\n",
        "        x = self.model(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWPa3cFR-Lr0"
      },
      "source": [
        "# 构建数据\n",
        "CFG = {\n",
        "    'img_size' : 512,\n",
        "    'epochs': 15,\n",
        "    'fold_num': 5,\n",
        "    'device': 'cpu',\n",
        "    'model_arch': 'tf_efficientnet_b4_ns',\n",
        "    'train_bs' : 2,\n",
        "    'valid_bs' : 2,\n",
        "    'num_workers' : 0,\n",
        "    'lr': 1e-4,\n",
        "    'weight_decay': 1e-6,\n",
        "    'T_0': 10,\n",
        "    'min_lr': 1e-6,\n",
        "}\n",
        "train = pd.read_csv(train_csv_path)\n",
        "folds = StratifiedKFold(n_splits=CFG['fold_num'],\n",
        "                        shuffle=True,\n",
        "                        random_state=rand_seed).split(\n",
        "                            np.arange(train.shape[0]), train.label.values)\n",
        "trn_transform = get_train_transforms()\n",
        "val_transform = get_valid_transforms()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t9tzO4rq-Lr0",
        "outputId": "d3a34095-9644-471e-8369-d349c2332003"
      },
      "source": [
        "fold_num = 0\n",
        "for fold, (trn_idx, val_idx) in enumerate(folds):\n",
        "    if fold == fold_num:\n",
        "        print('Training with {} started'.format(fold))\n",
        "        print('Train : {}, Val : {}'.format(len(trn_idx), len(val_idx)))\n",
        "        train_loader, val_loader = utils.prepare_dataloader(train,\n",
        "                                                          trn_idx,\n",
        "                                                          val_idx,\n",
        "                                                          data_root = train_img_path,\n",
        "                                                          trn_transform = trn_transform,\n",
        "                                                          val_transform = val_transform, \n",
        "                                                          bs = CFG['train_bs'], \n",
        "                                                          n_job = CFG['num_workers'])\n",
        "\n",
        "        device = torch.device(CFG['device'])\n",
        "\n",
        "        model = CassvaImgClassifier(CFG['model_arch'],\n",
        "                                    train.label.nunique(),\n",
        "                                    pretrained=True).to(device)\n",
        "        scaler = GradScaler()\n",
        "        optimizer = torch.optim.Adam(model.parameters(),\n",
        "                                     lr=CFG['lr'],\n",
        "                                     weight_decay=CFG['weight_decay'])\n",
        "\n",
        "        scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
        "            optimizer,\n",
        "            T_0=CFG['T_0'],\n",
        "            T_mult=1,\n",
        "            eta_min=CFG['min_lr'],\n",
        "            last_epoch=-1)\n",
        "\n",
        "        loss_tr = nn.CrossEntropyLoss().to(\n",
        "            device)\n",
        "        loss_fn = nn.CrossEntropyLoss().to(device)\n",
        "\n",
        "        for epoch in range(CFG['epochs']):\n",
        "            utils.train_one_epoch(epoch,\n",
        "                                model,\n",
        "                                loss_tr,\n",
        "                                optimizer,\n",
        "                                train_loader,\n",
        "                                device,\n",
        "                                scaler,\n",
        "                                scheduler=scheduler,\n",
        "                                schd_batch_update=False)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                utils.valid_one_epoch(epoch,\n",
        "                                    model,\n",
        "                                    loss_fn,\n",
        "                                    val_loader,\n",
        "                                    device)\n",
        "\n",
        "            torch.save(\n",
        "                model.state_dict(),\n",
        "                '../model/{}_fold_{}_{}'.format(CFG['model_arch'], fold, epoch))\n",
        "\n",
        "        del model, optimizer, train_loader, val_loader, scaler, scheduler\n",
        "        torch.cuda.empty_cache()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training with 0 started\n",
            "Train : 17117, Val : 4280\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/Users/wanjun/anaconda/envs/python36/lib/python3.6/site-packages/torch/cuda/amp/grad_scaler.py:115: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
            "  warnings.warn(\"torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\")\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/8559 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A/Users/wanjun/anaconda/envs/python36/lib/python3.6/site-packages/torch/cuda/amp/autocast_mode.py:114: UserWarning: torch.cuda.amp.autocast only affects CUDA ops, but CUDA is not available.  Disabling.\n",
            "  warnings.warn(\"torch.cuda.amp.autocast only affects CUDA ops, but CUDA is not available.  Disabling.\")\n",
            "\n",
            "\n",
            "\n",
            "epoch 0 loss: 1.6059:   0%|          | 0/8559 [00:07<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "epoch 0 loss: 1.6059:   0%|          | 1/8559 [00:07<18:46:41,  7.90s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "epoch 0 loss: 1.6060:   0%|          | 1/8559 [00:14<18:46:41,  7.90s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "epoch 0 loss: 1.6060:   0%|          | 2/8559 [00:14<17:35:07,  7.40s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m----------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m        Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-81-5cc2ef3384d2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     43\u001b[0m                                 \u001b[0mscaler\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m                                 \u001b[0mscheduler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m                                 schd_batch_update=False)\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/Desktop/比赛训练营/Kaggle木薯叶比赛/代码/code/src/utils/utils.py\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m(epoch, model, loss_fn, optimizer, train_loader, device, scaler, scheduler, schd_batch_update, accum_iter)\u001b[0m\n\u001b[1;32m    287\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_preds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_labels\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 计算 loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m         \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 对 loss scale, scale梯度\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0;31m# loss 正则,使用指数平均\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda/envs/python36/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda/envs/python36/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    130\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lT44oVd4-Lr2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}